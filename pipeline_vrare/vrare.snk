###################################################################################################################################
#
# Copyright 2019-2020 IRD-CNRS-Lyon1 University
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/> or
# write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston,
# MA 02110-1301, USA.
#
# You should have received a copy of the CeCILL-C license with this program.
# If not see <http://www.cecill.info/licences/Licence_CeCILL-C_V1-en.txt>
#
# Intellectual property belongs to authors and IRD, CNRS, and Lyon 1 University  for all versions
# Version 0.1 written by Mourdas Mohamed
#                                                                                                                                   
####################################################################################################################################



## Find path snakefile
path_snk = ""

i = 0
while i < len(sys.argv) and path_snk == "" :
    if sys.argv[i] == "--snakefile" :
        path_snk = sys.argv[i + 1]

    i += 1
#


rule TSD :
    input:
        total     = config["work_directory"].strip("/") + "/" + config["name_out"] + "_total_find.fasta",
        fasta_TE  = config["fasta_TE"],


    output:
        config["work_directory"].strip("/") + "/PICLUSTER/"  + config["genome"].split("/")[-1].split(".")[0] + "_IN_CLUSTER_COV_hit_map.csv",

    params:
        path_snk       = path_snk,
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),
        name_genome    = config["genome"].split("/")[-1].split(".")[0],

    shell:
        """

        echo '-----------TSD----------' ;
        mkdir -p {params.work_directory}/TSD ;
        path_to_pipline=`dirname {params.path_snk}`
        
        read_directory="{params.work_directory}/READ_FASTQ_{params.name_out}"
        fasta_dir_find="{params.work_directory}/FASTA_FIND"

        nb_file=`ls {params.work_directory}/ET_FIND_FA | wc -l` ;
        i=0 ;
        for TE_found_fa in `ls {params.work_directory}/ET_FIND_FA/`; do

            i=$(($i + 1)) ;
            echo $i/$nb_file ;
            sh ${{path_to_pipline}}/TSD/find_fq_to_fasta.sh {params.work_directory}/ET_FIND_FA/$TE_found_fa ${{read_directory}} ${{fasta_dir_find}} ;
            sh ${{path_to_pipline}}/TSD/tsd_te.sh {params.work_directory}/ET_FIND_FA/$TE_found_fa ${{read_directory}} ${{fasta_dir_find}} {input.fasta_TE} 10 4 ;
            name_te=`echo $TE_found_fa | grep -o "_[^_]*\." | grep -o "[^_]*" | sed 's/\.$//g'` ; 
            mv total_results_tsd.txt total_results_tsd_${{name_te}}.txt ;
            mv total_results_tsd_${{name_te}}.txt {params.work_directory}/TSD/ ;
        done;

        """


#Get pifluster flanking genes
rule picluster_flanking_genes :
    input:
        config["work_directory"].strip("/") + "/" + "resume.txt",
        genome    = config["genome"],
        all_te    = config["work_directory"].strip("/") + "/" + config["name_out"] + "_cnTE_ALL_ET.csv",
        snif_seqs = config["work_directory"].strip("/") + "/" + config["name_out"] + "_sniffle.fasta",

    output:
        config["work_directory"].strip("/") + "/PICLUSTER/"  + config["genome"].split("/")[-1].split(".")[0] + "_IN_CLUSTER_COV_hit_map.csv",

    params:
        path_snk       = path_snk,
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),
        name_genome    = config["genome"].split("/")[-1].split(".")[0],

    shell:
        """

        echo '-----------PiCluster----------' ;
        mkdir -p {params.work_directory} ;
        path_to_pipline=`dirname {params.path_snk}`
		
        makeblastdb -in {input.genome} -dbtype nucl ;
        blastn -db {input.genome} -query ${{path_to_pipline}}/data_test/picluster/genes_dm_picl.fasta -outfmt 6 -out {params.work_directory}/Gene_{params.name_genome}_full.bln ;
        
        python3 ${{path_to_pipline}}/scripts_python/picluster_gene.py {input.genome} {params.work_directory}/Gene_{params.name_genome}_full.bln ${{path_to_pipline}}/data_test/picluster/pair_genes.csv {input.all_te} ;
        #Rscript --vanilla ${{path_to_pipline}}/scripts_R/hit_pilcuster.R PICLUSTER/{params.name_genome}_IN_CLUSTER_COV_hit_map.csv ;
        mv PICLUSTER/ {params.work_directory}/

        """


#Get just sequence potentiel candidate of TE
rule get_TE_seq :
    input:
        config["work_directory"].strip("/") + "/" + "resume.txt",
        all_te    = config["work_directory"].strip("/") + "/" + config["name_out"] + "_cnTE_ALL_ET.csv",
        snif_seqs = config["work_directory"].strip("/") + "/" + config["name_out"] + "_sniffle.fasta",

    output:
        config["work_directory"].strip("/") + "/" + config["name_out"] + "_total_find.fasta",

    params:
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),

    shell:
        """
        mkdir -p {params.work_directory}/ET_FIND_FA ;
        
        rep="{params.work_directory}/ET_FIND_FA" 
        prefix="{params.name_out}"
        
        awk -v dir="$rep" -v prefix="$prefix" 'BEGIN{{OFS="\t"}} NR>1 {{if($8<$9){{print $2, $8-1, $9  >> dir"/"prefix"_find_"$1".bed"}}else{{print $2, $9-1, $8  >> dir"/"prefix"_find_"$1".bed"}} }}' {input.all_te} ;
        for i in `ls {params.work_directory}/ET_FIND_FA`; do bedtools getfasta -fi {input.snif_seqs} -bed {params.work_directory}/ET_FIND_FA/$i > {params.work_directory}/ET_FIND_FA/{params.name_out}_find_`echo G73_find_17.6.bed | grep -o "_[^_]*\." | grep -o "[^_]*" | sed 's/\.$//g'`.fasta; done ;
        
        rm -f {params.work_directory}/ET_FIND_FA/*.bed ;
        cat {params.work_directory}/ET_FIND_FA/* > {params.work_directory}/{params.name_out}_total_find.fasta ;
        """


#Get reads supports
rule extract_read :
    input:
        vcf    = config["work_directory"].strip("/") + "/" + config["name_out"] + ".vcf",
        read   = config["read"],
        all_te = config["work_directory"].strip("/") + "/" + config["name_out"] + "_cnTE_ALL_ET.csv",

    output:
        #config["work_directory"].strip("/") + "/" + "REGION_RD_" + config["name_out"],
        #config["work_directory"].strip("/") + "/" + "READ_FASTQ_" + config["name_out"] + "/reads_*",
        config["work_directory"].strip("/") + "/" + "resume.txt",

    params:
        path_snk       = path_snk,
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),


    shell:
        """
        echo '<<<<<<<<<<<<<<<< GET READS >>>>>>>>>>>>>>>>>>>>>>>' ;
        mkdir -p {params.work_directory} ;
        mkdir -p {params.work_directory}/READ_FASTQ_{params.name_out} ;

        path_to_pipline=`dirname {params.path_snk}`

        awk 'NR>1 {{print $2}}' {input.all_te} | cut -d":" -f 5 > {params.work_directory}/id.txt ; 
        python3 ${{path_to_pipline}}/scripts_python/extract_region_reads_vcf.py {input.vcf} -d {params.work_directory}/REGION_RD_{params.name_out} -i {params.work_directory}/id.txt > {params.work_directory}/resume.txt;
        
        cat {params.work_directory}/resume.txt;

        nb_file=`ls {params.work_directory}/REGION_RD_{params.name_out} | wc -l` ;
        i=0 ;
        for fr in `ls {params.work_directory}/REGION_RD_{params.name_out}`; do
            region=`echo $fr | grep -o "[_].*\." | grep -o "[^_].*[^.]"` ;
            i=$(($i + 1)) ;
            echo $i/$nb_file ;
            samtools fqidx {input.read} -r {params.work_directory}/REGION_RD_{params.name_out}/$fr > {params.work_directory}/READ_FASTQ_{params.name_out}/reads_$region.fastq ;
        done;

        NB_REGION=`ls {params.work_directory}/REGION_RD_{params.name_out} | wc -l` ;
        NB_READS=`ls {params.work_directory}/READ_FASTQ_{params.name_out} | wc -l` ;
        if [ $NB_REGION -ne $NB_READS ]; then rm -f {params.work_directory}/resume.txt ; echo 'Error : the number of files region it is not equal the number reads files'; fi;

        echo "$NB_READS AND $NB_REGION";

        """


#BLASt database of TE against SV (Structural variant)
rule blast :
    input:
        vcf      = config["work_directory"].strip("/") + "/" + config["name_out"] + ".vcf",
        fasta_TE = config["fasta_TE"],

    output:
        snif_seqs = config["work_directory"].strip("/") + "/" + config["name_out"] + "_sniffle.fasta",
        bln       = config["work_directory"].strip("/") + "/" + config["name_out"] + "_cnTE.bln",
        all_te    = config["work_directory"].strip("/") + "/" + config["name_out"] + "_cnTE_ALL_ET.csv",
        hitmap    = config["work_directory"].strip("/") + "/" + config["name_out"] + "_cnTE_ALL_ET_hit_map.csv",
        
    params:
        path_snk       = path_snk,
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),


    shell:
        """
        mkdir -p {params.work_directory} ;
        echo '<<<<<<<<<<<<<<<< BLAST >>>>>>>>>>>>>>>>>>>>>>>' ;

        path_to_pipline=`dirname {params.path_snk}`

        python3 ${{path_to_pipline}}/scripts_python/get_seq_vcf.py {input.vcf} {output.snif_seqs} ;

        makeblastdb -in {input.fasta_TE} -dbtype nucl ;
        blastn -db {input.fasta_TE} -query {output.snif_seqs} -outfmt 6 -out {output.bln} ;

        python3 ${{path_to_pipline}}/scripts_python/parse_blast_main.py {output.bln} {output.all_te} ;
        #Rscript --vanilla ${{path_to_pipline}}/scripts_R/hit_map_ET.R {output.hitmap} ;

        """


#Get Strucural Variant (vcf file)
rule sniffles :
    input:
        config["work_directory"].strip("/") + "/" + config["name_out"] + "_MD.sorted.bam",

    output:
        config["work_directory"].strip("/") + "/" + config["name_out"] + ".vcf",
        
    params:
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),

    shell:
        """
        mkdir -p {params.work_directory} ;
        echo '<<<<<<<<<<<<<<<< SNIFFLES >>>>>>>>>>>>>>>>>>>>>>>' ;
        sniffles --report_seq -s 1 -m {input} -v {output} -n -1 ;
        """


#Sort and callmd
rule samtools :
    input:
        sam    = config["work_directory"].strip("/") + "/" + config["name_out"] + ".sam",
        genome = config["genome"],

    output:
        config["work_directory"].strip("/") + "/" + config["name_out"] + "_MD.sorted.bam",
        
    params:
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),


    shell:
        """
        mkdir -p {params.work_directory} ;
        echo '<<<<<<<<<<<<<<<< SAMTOOLS >>>>>>>>>>>>>>>>>>>>>>>' ;

        samtools view -S -b {input.sam} > {params.work_directory}/{params.name_out}.bam ;
        samtools sort {params.work_directory}/{params.name_out}.bam -o {params.work_directory}/{params.name_out}.sorted.bam ;

        rm -f {params.name_out}.bam ;
        rm -f {input.sam} ;

        samtools calmd -b {params.work_directory}/{params.name_out}.sorted.bam {input.genome} > {output} ;
        """


#Map reads on assembly genome
rule mapping :
    input:  
        read   = config["read"],
        genome = config["genome"],

    output:
        config["work_directory"].strip("/") + "/" + config["name_out"] + ".sam",
        
    params:
        name_out       = config["name_out"],
        work_directory = config["work_directory"].strip("/"),

    shell:
        """
        mkdir -p {params.work_directory} ;
        echo '<<<<<<<<<<<<<<<<<<< INDEX >>>>>>>>>>>>>>>>>>>>' ;
        minimap2 -x map-ont -d {input.genome}.mmi {input.genome} ;
        echo '<<<<<<<<<<<<<<<<<<< MAPPING >>>>>>>>>>>>>>>>>>>>' ;
        minimap2 -ax map-ont -t 16 {input.genome} {input.read} > {output} ;
        """
        
